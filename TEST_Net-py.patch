--- a/TEST_Net.py	2024-11-21 17:37:30.063084453 +0100
+++ b/TEST_Net.py	2024-11-21 17:35:15.632605706 +0100
@@ -74,17 +74,20 @@
 	img[boolmask]=new_color
 
 def get_unique_classes(mask):
-	classes = np.unique(mask.reshape(-1, mask.shape[2]), axis=0)
+	uniques = np.unique(mask.reshape(-1, mask.shape[2]), axis=0, return_counts=True)
+	classes = uniques[0]
+	freqs   = uniques[1]
 	dbgprint(dataloader, LogLevel.INFO,  f"Num classes	: {len(classes)}")
 	dbgprint(dataloader, LogLevel.DEBUG, f"Classes		: {classes}")
-	return classes
+	return classes, freqs
 
-def replace_class_colors(mask, classes):
+def replace_class_colors(mask, classes, freqs=[]):
 	for idx,cls in enumerate(classes):
 		new_color = get_rgb_by_idx(idx)
 		new_name  = get_name_by_rgb(new_color)
-		dbgprint(dataloader, LogLevel.INFO, f"Class		: {idx} {cls} -> {new_color} ({new_name})")
-		replace_color(mask, cls, get_rgb_by_idx(idx))
+		extra_str = f' - {freqs[idx]} px' if len(freqs) > 0 else ''
+		dbgprint(dataloader, LogLevel.INFO, f"Class		: {idx} {cls} -> {new_color} ({new_name}{extra_str})")
+		replace_color(mask, cls, new_color)
 
 def read_image(image_path, mask_path):					# read and resize image and mask
 	if is_grayscale(image_path):
@@ -105,9 +108,10 @@
 	mask	= cv2.imread(mask_path, flag)				# mask of the region we want to segment
 	dbgprint(dataloader, LogLevel.INFO, f"Mask  shape	: {mask.shape}")
 
-	classes	= get_unique_classes(mask)
+	classes, freqs = get_unique_classes(mask)
 
-	replace_class_colors(mask, classes)
+	#replace_color(mask, [0, 0, 0], [64, 64, 64])
+	replace_class_colors(mask, classes, freqs=freqs)
 
 	if debug_masks:
 		submask = mask[280:330, 280:330]
@@ -226,9 +230,10 @@
 		for imgfn, mskfn in zip(image_files, mask_files):
 			dbgprint(dataloader, LogLevel.INFO, f"Loading images	: {Path(imgfn).name} - {Path(mskfn).name}")
 			image, mask	= read_image(imgfn, mskfn)
-			cv2.imshow(f"image", image)
-			cv2.imshow(f"mask", mask)
-			cv2.waitKey()
+			if debug_masks or True:
+				cv2.imshow(f"image", image)
+				cv2.imshow(f"mask", mask[...,::-1])
+				cv2.waitKey()
 			input_points	= get_points(mask, num_samples)	# read image and sample points
 			dataset.append((image, mask, input_points, imgfn, mskfn))
 
