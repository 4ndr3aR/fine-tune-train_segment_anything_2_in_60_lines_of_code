I have a list of RGB+instance segmantation image pairs (both of them .png) and I have to compute a instance segmentation loss to train my model. To have the loss, I first have to convert both gt_mask and pred_mask (both RGB masks with shape (3,H,W)) into binary masks. To do that I have to lookup a .txt file (in the instance_segmentation directory, together with the mask .png file) that holds the info about all the "relevant instances" in the mask (only trees in this dataset):
`
Tree44 11
Tree31 41
Tree52 107
Tree158 87
Tree87 75
Tree11 76
Tree77 25
Tree156 86
Tree106 5
Tree127 42
Tree161 108
Tree167 113
Tree111 36
Tree6 73
Tree66 134
Tree132 38
Tree23 54
Tree150 140
Tree157 59
Tree64 133
Tree166 119
Tree61 112
Tree0 114
Tree43 26
Tree41 35
Tree39 64
Tree28 66
Tree129 29
Tree60 120
Tree53 17
Tree99 1
Tree75 45
Tree27 57
Tree40 52
Tree92 15
Tree72 47
Tree13 65
Tree18 116
Tree30 48
Tree9 56
Tree14 88
Tree47 94
Tree17 111
Tree26 68
Tree128 21
Tree118 118
Tree78 49
Tree164 101
Tree12 102
Tree109 43
Tree51 105
Tree98 2
Tree59 125
Tree149 131
Tree168 117
Tree84 85
Tree45 8
Tree153 99
Tree8 103
Tree42 79
Tree116 123
Tree1 63
Tree67 141
Tree70 139
Tree21 61
Tree80 91
Tree37 23
Tree88 82
Tree143 124
Tree108 7
Tree105 115
Tree107 3
Tree85 95
Tree171 135
Tree97 6
Tree169 126
Tree76 34
Tree119 137
Tree154 62
Tree81 58
Tree79 16
Tree131 28
Tree3 53
Tree2 93
Tree35 12
Tree110 32
Tree48 92
Tree96 46
Tree22 69
Tree50 106
Tree24 67
Tree25 90
Tree19 104
Tree57 22
Tree74 27
Tree172 136
Tree90 84
Tree49 96
Tree38 89
Tree170 130
Tree29 78
Tree117 138
Tree32 72
Tree89 71
Tree160 98
Tree121 128
Tree155 74
Tree4 83
Tree56 14
Tree100 4
Tree86 20
Tree46 18
Tree58 9
Tree159 109
Tree15 60
Tree83 70
Tree5 50
Tree34 31
Tree71 132
Tree10 121
Tree94 24
Tree93 55
Tree36 10
Tree16 81
Tree104 122
Tree133 39
Tree33 80
Tree82 77
Tree130 19
Tree91 97
Tree54 33
Tree7 51
Tree112 30
Tree165 110
Tree95 44
Tree115 129
Tree55 13
Tree73 37
Tree20 100
Tree69 127
Tree113 40
`

The info file is made of pairs of <obj_id> <color_id>, and the <color_id> in turn can be looked up in the color_palette list of dictionaries (in the form [{0: [55, 181, 57]}, {1: [153, 108, 6]}, {2: [112, 105, 191]}, ... ]). But there's a catch! The info file contains only trees, but the instance segmentation masks contain a lot more objects (a few of them may be quite large, like walls, sky, grass, etc.) and it's important to segment them too. So the algoritm should take into account all the "valid" colors present in the color_palette dictionary while extracting the binary masks. Every other (invalid) color should be put to black. Before performing the instance segmentation loss calculation, given that the valid colors can be a maximum of 256, also convert all the colors in the info file to 0-255 range using the color_palette dictionary and filling a gray_color_palette dictionary. To recap: write all the functions necessary to perform this pipeline. For sure write a function to extract binary masks (with type torch bool) from RGB instance segmentation masks (with type torch uint8) using all the information available in both the info file (with the same name of the instance segmentation mask but .txt extension) and the color_palette dictionary, while performing the grayscale conversion according to the valid colors present in the mask. Remember to extract both "tree" masks and "non-tree" masks and also keep track of the labels in some way. Then write a loss function that performs the crossentropy loss binary mask by binary mask (matching the same colors) and returns the instance segmentation loss.
